package sparktest;
import scala.Tuple2;

import org.apache.spark.api.java.*;
import org.apache.spark.api.java.function.Function;
import org.apache.spark.mllib.recommendation.ALS;
import org.apache.spark.mllib.recommendation.MatrixFactorizationModel;
import org.apache.spark.mllib.recommendation.Rating;
import org.apache.spark.SparkConf;

public class CollaborativeFiltering {
  public static void main(String[] args) {
    SparkConf conf = new SparkConf().setAppName("Collaborative Filtering Example");
    JavaSparkContext sc = new JavaSparkContext(conf.setMaster("local").setAppName("CollaborativeFiltering"));
    // Load and parse the data
    String path = "F:\\MyStudy\\ml-100k\\u.data";
    JavaRDD<String> data = sc.textFile(path);
    JavaRDD<Rating> ratings = data.map(
      new Function<String, Rating>() {
        public Rating call(String s) {
          String[] sarray = s.split("[^0-9]");
          return new Rating(Integer.parseInt(sarray[0]), Integer.parseInt(sarray[1]), 
                            Double.parseDouble(sarray[2]));
        }
      }
    );
    
    JavaRDD<Rating>[] dataParts = ratings.randomSplit(new double[]{0.8,0.2});
    JavaRDD<Rating> trainingRDD = dataParts[0];
    JavaRDD<Rating> testRDD = dataParts[1];

    // Build the recommendation model using ALS
    int rank = 5;
    int numIterations = 10;
    //MatrixFactorizationModel model = ALS.train(JavaRDD.toRDD(ratings), rank, numIterations, 0.01); 
    MatrixFactorizationModel model = ALS.train(trainingRDD.rdd(), rank, numIterations, 0.01); 

    // Evaluate the model on rating data
    JavaRDD<Tuple2<Object, Object>> userProducts = testRDD.map(//将返回的Tuple2<Object, Object>类型的参数放到JavaRDD中去
    	//Tuple2<Object, Object>为返回类型，Rating为输入参数类型
      new Function<Rating, Tuple2<Object, Object>>() {
        public Tuple2<Object, Object> call(Rating r) {
        	//获取Rating r中的user和product两个参数
          return new Tuple2<Object, Object>(r.user(), r.product());
        }
      }
    );
    //model.predict来预测
    JavaPairRDD<Tuple2<Integer, Integer>, Double> predictions = JavaPairRDD.fromJavaRDD(
      model.predict(JavaRDD.toRDD(userProducts)).toJavaRDD().map(
    		  // Tuple2<Tuple2<Integer, Integer>, Double>是返回类型，Rating是输入类型
        new Function<Rating, Tuple2<Tuple2<Integer, Integer>, Double>>() {
          public Tuple2<Tuple2<Integer, Integer>, Double> call(Rating r){
            return new Tuple2<Tuple2<Integer, Integer>, Double>(
            		//获取Rating r中的user、product和rating三个参数
              new Tuple2<Integer, Integer>(r.user(), r.product()), r.rating());
          }
        }
    ));
    JavaRDD<Tuple2<Double, Double>> ratesAndPreds = 
      JavaPairRDD.fromJavaRDD(testRDD.map(
        new Function<Rating, Tuple2<Tuple2<Integer, Integer>, Double>>() {
          public Tuple2<Tuple2<Integer, Integer>, Double> call(Rating r){
            return new Tuple2<Tuple2<Integer, Integer>, Double>(
              new Tuple2<Integer, Integer>(r.user(), r.product()), r.rating());
          }
        }
        //join(predictions)预测和实际值归并；values()只要rating部分
    )).join(predictions).values();
    //对ratesAndPreds中的两个值进行计算方差
    double MSE = JavaDoubleRDD.fromRDD(ratesAndPreds.map(
      new Function<Tuple2<Double, Double>, Object>() {
        public Object call(Tuple2<Double, Double> pair) {
          Double err = pair._1() - pair._2();
          return err * err;
        }
      }
    ).rdd()).mean();
    System.out.println("Mean Squared Error = " + MSE);

    // Save and load model
    //model.save(sc.sc(), "myModelPath");
    //MatrixFactorizationModel sameModel = MatrixFactorizationModel.load(sc.sc(), "myModelPath");
  }
}
