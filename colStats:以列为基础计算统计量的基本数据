package sparktest;

import java.util.Arrays;

import org.apache.spark.SparkConf;
import org.apache.spark.api.java.JavaRDD;
import org.apache.spark.api.java.JavaSparkContext;
import org.apache.spark.mllib.linalg.Vector;
import org.apache.spark.mllib.linalg.Vectors;
import org.apache.spark.mllib.stat.MultivariateStatisticalSummary;
import org.apache.spark.mllib.stat.Statistics;

public class StatisticsColStatsLearning {
	//colStats:以列为基础计算统计量的基本数据
	public static void main(String[] args) {
		SparkConf conf = new SparkConf().setMaster("local").setAppName("StatisticsColStatsLearning");
		JavaSparkContext jsc = new JavaSparkContext(conf);
		JavaRDD<Vector> mat = jsc.parallelize(Arrays.asList(Vectors.dense(1.0, 10.0, 100.0),
				//dense:生成稠密矩阵
				Vectors.dense(2.0, 20.0, 200.0), Vectors.dense(3.0, 30.0, 300.0))); // an RDD of Vectors

		// Compute column summary statistics.按列来统计
		MultivariateStatisticalSummary summary = Statistics.colStats(mat.rdd());
		System.out.println(summary.mean()); // a dense vector containing the mean value for each column，每列的均值
		System.out.println(summary.variance()); // column-wise variance，协方差
		System.out.println(summary.numNonzeros()); // number of nonzeros in each column，每列的非零的个数

	}

}
